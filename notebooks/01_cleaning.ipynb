{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"# To Bleach or Not to Bleach? \\n\",\n",
    "    \"\\n\",\n",
    "    \"## Quickstart Notebook\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Goal:** identify drivers of coral bleaching and predict the percentage of coral that is bleached (`Percent_Bleached`).  \\n\",\n",
    "    \"**Dataset:** csv file with site-level (aka \\\"location\\\"/coral reef) grouping by `Site_ID`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Cleaning\\n\",\n",
    "    \"\\n\",\n",
    "    \"*Oh no, the data seems to be corrupted!* It looks like the people from the fossil fuel industry have been tampering with the data. There are some missing values, some outliers, and invalid/duplicate rows. **Start by cleaning it up!**\\n\"\n",
    "   ],\n",
    "   \"id\": \"f843131c44c80d92\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Imports\",\n",
    "   \"id\": \"6076681a996e5815\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-12T10:15:54.011422Z\",\n",
    "     \"start_time\": \"2025-11-12T10:15:53.865360Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from typing import Iterable, Dict, Tuple, Literal\\n\",\n",
    "    \"from sklearn.impute import KNNImputer\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\"\n",
    "   ],\n",
    "   \"id\": \"d8e175f886f46d4\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 1\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Reusable functions\",\n",
    "   \"id\": \"7722073d84429d2b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-12T10:15:56.670667Z\",\n",
    "     \"start_time\": \"2025-11-12T10:15:56.659002Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"Strategy = Literal[\\\"impute\\\", \\\"drop\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"def iqr_mask(df: pd.DataFrame, columns: Iterable[str], k: float = 1.5) -> Dict[str, pd.Series]:\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Return a boolean mask per selected column: True where value is an IQR outlier.\\n\",\n",
    "    \"    k=1.5 -> Tukey 'mild' outliers; use 3.0 for 'extreme'.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    masks: Dict[str, pd.Series] = {}\\n\",\n",
    "    \"    for col in columns:\\n\",\n",
    "    \"        s = pd.to_numeric(df[col], errors=\\\"coerce\\\")\\n\",\n",
    "    \"        q1 = s.quantile(0.25)\\n\",\n",
    "    \"        q3 = s.quantile(0.75)\\n\",\n",
    "    \"        iqr = q3 - q1\\n\",\n",
    "    \"        if pd.isna(iqr) or iqr == 0:\\n\",\n",
    "    \"            masks[col] = pd.Series(False, index=df.index)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            lower = q1 - k * iqr\\n\",\n",
    "    \"            upper = q3 + k * iqr\\n\",\n",
    "    \"            masks[col] = (s < lower) | (s > upper)\\n\",\n",
    "    \"    return masks\\n\",\n",
    "    \"\\n\",\n",
    "    \"def clean_outliers(\\n\",\n",
    "    \"    df: pd.DataFrame,\\n\",\n",
    "    \"    outlier_columns: Iterable[str],\\n\",\n",
    "    \"    *,\\n\",\n",
    "    \"    k_iqr: float = 1.5,\\n\",\n",
    "    \"    strategy: Strategy = \\\"impute\\\",\\n\",\n",
    "    \"    n_neighbors: int = 5,\\n\",\n",
    "    \"    weights: str = \\\"distance\\\",\\n\",\n",
    "    \"    output_csv: str | None = None,\\n\",\n",
    "    \") -> Tuple[pd.DataFrame, pd.Series]:\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Pipeline:\\n\",\n",
    "    \"      1) Mark IQR outliers in `outlier_columns` -> NaN\\n\",\n",
    "    \"      2) strategy == 'impute': KNN-impute numeric columns (scaled)\\n\",\n",
    "    \"         strategy == 'drop'  : drop rows having NaN in any of `outlier_columns`\\n\",\n",
    "    \"      3) Drop any remaining NaNs (whole-row drop)\\n\",\n",
    "    \"    Returns: (clean_df, outlier_row_mask_before_cleaning)\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    df_work = df.copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 1) Detect outliers & set to NaN (only in requested columns)\\n\",\n",
    "    \"    masks = iqr_mask(df_work, outlier_columns, k=k_iqr)\\n\",\n",
    "    \"    mask_df = pd.DataFrame(masks, index=df_work.index) if masks else pd.DataFrame(index=df_work.index)\\n\",\n",
    "    \"    any_outlier = mask_df.any(axis=1) if not mask_df.empty else pd.Series(False, index=df_work.index)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for col, m in masks.items():\\n\",\n",
    "    \"        df_work.loc[m, col] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 2) Clean by strategy\\n\",\n",
    "    \"    if strategy == \\\"impute\\\":\\n\",\n",
    "    \"        num_cols = df_work.select_dtypes(include=\\\"number\\\").columns.tolist()\\n\",\n",
    "    \"        if num_cols:\\n\",\n",
    "    \"            scaler = StandardScaler()\\n\",\n",
    "    \"            imputer = KNNImputer(n_neighbors=n_neighbors, weights=weights)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            X_num = df_work[num_cols].astype(float).values\\n\",\n",
    "    \"            X_scaled = scaler.fit_transform(X_num)\\n\",\n",
    "    \"            X_imputed_scaled = imputer.fit_transform(X_scaled)\\n\",\n",
    "    \"            X_imputed = scaler.inverse_transform(X_imputed_scaled)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            df_work[num_cols] = X_imputed\\n\",\n",
    "    \"    elif strategy == \\\"drop\\\":\\n\",\n",
    "    \"        df_work = df_work.dropna(subset=list(outlier_columns), how=\\\"any\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        raise ValueError(\\\"strategy must be 'impute' or 'drop'\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 3) Drop any remaining NaNs anywhere (whole row)\\n\",\n",
    "    \"    df_clean = df_work.dropna(axis=0, how=\\\"any\\\").reset_index(drop=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if output_csv:\\n\",\n",
    "    \"        df_clean.to_csv(output_csv, index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return df_clean, any_outlier\\n\"\n",
    "   ],\n",
    "   \"id\": \"76aa7921053b57f8\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 2\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"### Data cleaning\\n\",\n",
    "    \"\\n\",\n",
    "    \"Reading the csv\"\n",
    "   ],\n",
    "   \"id\": \"6245a29397238a28\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-12T10:15:59.734934Z\",\n",
    "     \"start_time\": \"2025-11-12T10:15:59.694Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"filepath_train = r\\\"../data/coral_students.csv\\\"\\n\",\n",
    "    \"df = pd.read_csv(filepath_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df.head()\"\n",
    "   ],\n",
    "   \"id\": \"1d936fb21362b05e\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"    Sample_ID  Site_ID  ClimSST  Temperature_Kelvin  Temperature_Mean  \\\\\\n\",\n",
    "       \"0  10274495.0  12082.0   301.65              303.50            299.79   \\n\",\n",
    "       \"1  10274496.0  12083.0   299.31              300.84            299.75   \\n\",\n",
    "       \"2  10274497.0  12084.0   300.56              302.65            299.81   \\n\",\n",
    "       \"3  10274498.0  12085.0   299.75              302.43            299.81   \\n\",\n",
    "       \"4  10274499.0  12086.0   297.65              295.69            299.81   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   Temperature_Minimum  Temperature_Maximum  \\\\\\n\",\n",
    "       \"0               293.35               305.54   \\n\",\n",
    "       \"1               293.68               305.44   \\n\",\n",
    "       \"2               293.35               305.47   \\n\",\n",
    "       \"3               293.35               305.47   \\n\",\n",
    "       \"4               293.35               305.47   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   Temperature_Kelvin_Standard_Deviation  Windspeed  SSTA  ...  TSA_DHW  \\\\\\n\",\n",
    "       \"0                                   2.52        2.0  0.49  ...     1.27   \\n\",\n",
    "       \"1                                   2.54        6.0 -0.42  ...     1.20   \\n\",\n",
    "       \"2                                   2.50        5.0  0.36  ...     2.71   \\n\",\n",
    "       \"3                                   2.50        7.0  0.54  ...     3.60   \\n\",\n",
    "       \"4                                   2.50        7.0 -0.91  ...     0.00   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   TSA_DHW_Standard_Deviation  TSA_DHWMax  TSA_DHWMean  Depth_m  \\\\\\n\",\n",
    "       \"0                        0.74        6.05         0.22      8.3   \\n\",\n",
    "       \"1                        0.93       10.39         0.27     14.9   \\n\",\n",
    "       \"2                        0.83        7.18         0.23     10.7   \\n\",\n",
    "       \"3                        0.83        7.18         0.23      7.6   \\n\",\n",
    "       \"4                        0.83        7.18         0.23     10.0   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   Distance_to_Shore  Exposure  Turbidity  Cyclone_Frequency  Percent_Bleached  \\n\",\n",
    "       \"0             8311.0   exposed     0.0586          56.583448              4.76  \\n\",\n",
    "       \"1            10747.0   exposed     0.0543          52.842523             21.88  \\n\",\n",
    "       \"2             9396.0   exposed     0.0571          56.583448             19.66  \\n\",\n",
    "       \"3             9408.0   exposed     0.0571          56.583448             28.03  \\n\",\n",
    "       \"4             9362.0   exposed     0.0571          56.583448              2.75  \\n\",\n",
    "       \"\\n\",\n",
    "       \"[5 rows x 41 columns]\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>Sample_ID</th>\\n\",\n",
    "       \"      <th>Site_ID</th>\\n\",\n",
    "       \"      <th>ClimSST</th>\\n\",\n",
    "       \"      <th>Temperature_Kelvin</th>\\n\",\n",
    "       \"      <th>Temperature_Mean</th>\\n\",\n",
    "       \"      <th>Temperature_Minimum</th>\\n\",\n",
    "       \"      <th>Temperature_Maximum</th>\\n\",\n",
    "       \"      <th>Temperature_Kelvin_Standard_Deviation</th>\\n\",\n",
    "       \"      <th>Windspeed</th>\\n\",\n",
    "       \"      <th>SSTA</th>\\n\",\n",
    "       \"      <th>...</th>\\n\",\n",
    "       \"      <th>TSA_DHW</th>\\n\",\n",
    "       \"      <th>TSA_DHW_Standard_Deviation</th>\\n\",\n",
    "       \"      <th>TSA_DHWMax</th>\\n\",\n",
    "       \"      <th>TSA_DHWMean</th>\\n\",\n",
    "       \"      <th>Depth_m</th>\\n\",\n",
    "       \"      <th>Distance_to_Shore</th>\\n\",\n",
    "       \"      <th>Exposure</th>\\n\",\n",
    "       \"      <th>Turbidity</th>\\n\",\n",
    "       \"      <th>Cyclone_Frequency</th>\\n\",\n",
    "       \"      <th>Percent_Bleached</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>10274495.0</td>\\n\",\n",
    "       \"      <td>12082.0</td>\\n\",\n",
    "       \"      <td>301.65</td>\\n\",\n",
    "       \"      <td>303.50</td>\\n\",\n",
    "       \"      <td>299.79</td>\\n\",\n",
    "       \"      <td>293.35</td>\\n\",\n",
    "       \"      <td>305.54</td>\\n\",\n",
    "       \"      <td>2.52</td>\\n\",\n",
    "       \"      <td>2.0</td>\\n\",\n",
    "       \"      <td>0.49</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>1.27</td>\\n\",\n",
    "       \"      <td>0.74</td>\\n\",\n",
    "       \"      <td>6.05</td>\\n\",\n",
    "       \"      <td>0.22</td>\\n\",\n",
    "       \"      <td>8.3</td>\\n\",\n",
    "       \"      <td>8311.0</td>\\n\",\n",
    "       \"      <td>exposed</td>\\n\",\n",
    "       \"      <td>0.0586</td>\\n\",\n",
    "       \"      <td>56.583448</td>\\n\",\n",
    "       \"      <td>4.76</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>10274496.0</td>\\n\",\n",
    "       \"      <td>12083.0</td>\\n\",\n",
    "       \"      <td>299.31</td>\\n\",\n",
    "       \"      <td>300.84</td>\\n\",\n",
    "       \"      <td>299.75</td>\\n\",\n",
    "       \"      <td>293.68</td>\\n\",\n",
    "       \"      <td>305.44</td>\\n\",\n",
    "       \"      <td>2.54</td>\\n\",\n",
    "       \"      <td>6.0</td>\\n\",\n",
    "       \"      <td>-0.42</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>1.20</td>\\n\",\n",
    "       \"      <td>0.93</td>\\n\",\n",
    "       \"      <td>10.39</td>\\n\",\n",
    "       \"      <td>0.27</td>\\n\",\n",
    "       \"      <td>14.9</td>\\n\",\n",
    "       \"      <td>10747.0</td>\\n\",\n",
    "       \"      <td>exposed</td>\\n\",\n",
    "       \"      <td>0.0543</td>\\n\",\n",
    "       \"      <td>52.842523</td>\\n\",\n",
    "       \"      <td>21.88</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>10274497.0</td>\\n\",\n",
    "       \"      <td>12084.0</td>\\n\",\n",
    "       \"      <td>300.56</td>\\n\",\n",
    "       \"      <td>302.65</td>\\n\",\n",
    "       \"      <td>299.81</td>\\n\",\n",
    "       \"      <td>293.35</td>\\n\",\n",
    "       \"      <td>305.47</td>\\n\",\n",
    "       \"      <td>2.50</td>\\n\",\n",
    "       \"      <td>5.0</td>\\n\",\n",
    "       \"      <td>0.36</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>2.71</td>\\n\",\n",
    "       \"      <td>0.83</td>\\n\",\n",
    "       \"      <td>7.18</td>\\n\",\n",
    "       \"      <td>0.23</td>\\n\",\n",
    "       \"      <td>10.7</td>\\n\",\n",
    "       \"      <td>9396.0</td>\\n\",\n",
    "       \"      <td>exposed</td>\\n\",\n",
    "       \"      <td>0.0571</td>\\n\",\n",
    "       \"      <td>56.583448</td>\\n\",\n",
    "       \"      <td>19.66</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>10274498.0</td>\\n\",\n",
    "       \"      <td>12085.0</td>\\n\",\n",
    "       \"      <td>299.75</td>\\n\",\n",
    "       \"      <td>302.43</td>\\n\",\n",
    "       \"      <td>299.81</td>\\n\",\n",
    "       \"      <td>293.35</td>\\n\",\n",
    "       \"      <td>305.47</td>\\n\",\n",
    "       \"      <td>2.50</td>\\n\",\n",
    "       \"      <td>7.0</td>\\n\",\n",
    "       \"      <td>0.54</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>3.60</td>\\n\",\n",
    "       \"      <td>0.83</td>\\n\",\n",
    "       \"      <td>7.18</td>\\n\",\n",
    "       \"      <td>0.23</td>\\n\",\n",
    "       \"      <td>7.6</td>\\n\",\n",
    "       \"      <td>9408.0</td>\\n\",\n",
    "       \"      <td>exposed</td>\\n\",\n",
    "       \"      <td>0.0571</td>\\n\",\n",
    "       \"      <td>56.583448</td>\\n\",\n",
    "       \"      <td>28.03</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>10274499.0</td>\\n\",\n",
    "       \"      <td>12086.0</td>\\n\",\n",
    "       \"      <td>297.65</td>\\n\",\n",
    "       \"      <td>295.69</td>\\n\",\n",
    "       \"      <td>299.81</td>\\n\",\n",
    "       \"      <td>293.35</td>\\n\",\n",
    "       \"      <td>305.47</td>\\n\",\n",
    "       \"      <td>2.50</td>\\n\",\n",
    "       \"      <td>7.0</td>\\n\",\n",
    "       \"      <td>-0.91</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>0.00</td>\\n\",\n",
    "       \"      <td>0.83</td>\\n\",\n",
    "       \"      <td>7.18</td>\\n\",\n",
    "       \"      <td>0.23</td>\\n\",\n",
    "       \"      <td>10.0</td>\\n\",\n",
    "       \"      <td>9362.0</td>\\n\",\n",
    "       \"      <td>exposed</td>\\n\",\n",
    "       \"      <td>0.0571</td>\\n\",\n",
    "       \"      <td>56.583448</td>\\n\",\n",
    "       \"      <td>2.75</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"<p>5 rows Ã— 41 columns</p>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 3,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 3\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Checking the structure of data\",\n",
    "   \"id\": \"553a03121d6bdfdd\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-12T10:16:02.239651Z\",\n",
    "     \"start_time\": \"2025-11-12T10:16:02.233851Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"print(df.shape)\\n\",\n",
    "    \"df.isna().sum()\"\n",
    "   ],\n",
    "   \"id\": \"7a6b36a9f550e8bd\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"(4446, 41)\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Sample_ID                                  1\\n\",\n",
    "       \"Site_ID                                    1\\n\",\n",
    "       \"ClimSST                                    1\\n\",\n",
    "       \"Temperature_Kelvin                         1\\n\",\n",
    "       \"Temperature_Mean                           1\\n\",\n",
    "       \"Temperature_Minimum                        1\\n\",\n",
    "       \"Temperature_Maximum                        1\\n\",\n",
    "       \"Temperature_Kelvin_Standard_Deviation      1\\n\",\n",
    "       \"Windspeed                                  1\\n\",\n",
    "       \"SSTA                                       1\\n\",\n",
    "       \"SSTA_Standard_Deviation                    1\\n\",\n",
    "       \"SSTA_Mean                                  1\\n\",\n",
    "       \"SSTA_Minimum                               1\\n\",\n",
    "       \"SSTA_Maximum                               1\\n\",\n",
    "       \"SSTA_Frequency                             1\\n\",\n",
    "       \"SSTA_Frequency_Standard_Deviation          1\\n\",\n",
    "       \"SSTA_FrequencyMax                          1\\n\",\n",
    "       \"SSTA_FrequencyMean                         1\\n\",\n",
    "       \"SSTA_DHW                                   1\\n\",\n",
    "       \"SSTA_DHW_Standard_Deviation                1\\n\",\n",
    "       \"SSTA_DHWMax                                1\\n\",\n",
    "       \"SSTA_DHWMean                               1\\n\",\n",
    "       \"TSA                                        1\\n\",\n",
    "       \"TSA_Standard_Deviation                     1\\n\",\n",
    "       \"TSA_Minimum                                1\\n\",\n",
    "       \"TSA_Maximum                                1\\n\",\n",
    "       \"TSA_Mean                                   1\\n\",\n",
    "       \"TSA_Frequency                              1\\n\",\n",
    "       \"TSA_Frequency_Standard_Deviation           1\\n\",\n",
    "       \"TSA_FrequencyMax                           1\\n\",\n",
    "       \"TSA_FrequencyMean                          1\\n\",\n",
    "       \"TSA_DHW                                    1\\n\",\n",
    "       \"TSA_DHW_Standard_Deviation                 1\\n\",\n",
    "       \"TSA_DHWMax                                 1\\n\",\n",
    "       \"TSA_DHWMean                                1\\n\",\n",
    "       \"Depth_m                                  185\\n\",\n",
    "       \"Distance_to_Shore                          1\\n\",\n",
    "       \"Exposure                                   1\\n\",\n",
    "       \"Turbidity                                  1\\n\",\n",
    "       \"Cyclone_Frequency                          1\\n\",\n",
    "       \"Percent_Bleached                           1\\n\",\n",
    "       \"dtype: int64\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 4,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 4\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Searching for duplicate rows\",\n",
    "   \"id\": \"24f668eee7c544f7\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-12T10:16:14.231562Z\",\n",
    "     \"start_time\": \"2025-11-12T10:16:14.217907Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"uniqueId = [\\\"Sample_ID\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 1) Exact row duplicates\\n\",\n",
    "    \"dups = df[df.duplicated(subset=uniqueId, keep=False)]          # all duplicate rows\\n\",\n",
    "    \"df_no_dups = df.drop_duplicates(subset=uniqueId, keep=\\\"first\\\") # keep first occurrence\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 2) Duplicates by subset of columns (business key)\\n\",\n",
    "    \"dups_by_key = df[df.duplicated(subset=uniqueId, keep=False)]\\n\",\n",
    "    \"firsts = df.drop_duplicates(subset=uniqueId, keep=\\\"first\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 3) Mark duplicates instead of dropping\\n\",\n",
    "    \"df[\\\"is_dup\\\"] = df.duplicated(subset=uniqueId, keep=\\\"first\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 4) Count duplicate groups\\n\",\n",
    "    \"dup_counts = (df\\n\",\n",
    "    \"  .groupby(uniqueId, dropna=False)\\n\",\n",
    "    \"  .size()\\n\",\n",
    "    \"  .reset_index(name=\\\"count\\\")\\n\",\n",
    "    \"  .query(\\\"count > 1\\\"))\\n\",\n",
    "    \"print(dup_counts)\"\n",
    "   ],\n",
    "   \"id\": \"f1d64bfc50ca9a03\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"       Sample_ID  count\\n\",\n",
    "      \"125   10274739.0      2\\n\",\n",
    "      \"311   10275110.0      2\\n\",\n",
    "      \"376   10275267.0      2\\n\",\n",
    "      \"918   10276398.0      2\\n\",\n",
    "      \"1236  10290633.0      2\\n\",\n",
    "      \"1267  10322434.0      2\\n\",\n",
    "      \"1424  10323868.0      2\\n\",\n",
    "      \"2231  10326707.0      2\\n\",\n",
    "      \"2246  10326723.0      2\\n\",\n",
    "      \"2263  10326760.0      2\\n\",\n",
    "      \"2267  10326765.0      2\\n\",\n",
    "      \"2310  10326841.0      2\\n\",\n",
    "      \"2318  10326849.0      2\\n\",\n",
    "      \"2570  10327590.0      2\\n\",\n",
    "      \"2672  10327888.0      2\\n\",\n",
    "      \"2749  10328138.0      2\\n\",\n",
    "      \"2830  10328411.0      2\\n\",\n",
    "      \"2838  10328421.0      2\\n\",\n",
    "      \"2878  10328513.0      2\\n\",\n",
    "      \"3206  10329203.0      2\\n\",\n",
    "      \"3365  10329491.0      2\\n\",\n",
    "      \"3552  10329892.0      2\\n\",\n",
    "      \"3629  10329992.0      2\\n\",\n",
    "      \"3634  10330006.0      2\\n\",\n",
    "      \"3856  10330530.0      2\\n\",\n",
    "      \"3866  10330547.0      4\\n\",\n",
    "      \"3878  10330569.0      2\\n\",\n",
    "      \"3953  10330776.0      4\\n\",\n",
    "      \"3994  10330878.0      4\\n\",\n",
    "      \"4227  10331344.0      2\\n\",\n",
    "      \"4368  10331601.0      2\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 5\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Removing duplicates\",\n",
    "   \"id\": \"c683816ebd61a667\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-12T10:16:17.546219Z\",\n",
    "     \"start_time\": \"2025-11-12T10:16:17.538967Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": \"df = df.drop_duplicates(subset=[\\\"Sample_ID\\\"], keep=\\\"first\\\").reset_index(drop=True)\",\n",
    "   \"id\": \"3e680e79667993ad\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 6\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Searching for outliers\",\n",
    "   \"id\": \"68b87154170d3462\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-12T10:16:18.779860Z\",\n",
    "     \"start_time\": \"2025-11-12T10:16:18.759767Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"cols = [\\n\",\n",
    "    \"    \\\"Temperature_Kelvin\\\", \\\"Temperature_Mean\\\", \\\"Temperature_Minimum\\\",\\n\",\n",
    "    \"    \\\"Temperature_Maximum\\\", \\\"Temperature_Kelvin_Standard_Deviation\\\",\\n\",\n",
    "    \"    \\\"Windspeed\\\", \\\"Depth_m\\\", \\\"Distance_to_Shore\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"masks = iqr_mask(df, cols, k=1.5)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_flagged = df.copy()\\n\",\n",
    "    \"for col, m in masks.items():\\n\",\n",
    "    \"    df_flagged[f\\\"{col}_is_outlier\\\"] = m\\n\",\n",
    "    \"\\n\",\n",
    "    \"if masks:\\n\",\n",
    "    \"    df_flagged[\\\"any_outlier\\\"] = pd.concat(masks.values(), axis=1).any(axis=1)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    df_flagged[\\\"any_outlier\\\"] = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"outlier_rows = df_flagged[df_flagged[\\\"any_outlier\\\"]]\\n\",\n",
    "    \"print(outlier_rows.count())\\n\"\n",
    "   ],\n",
    "   \"id\": \"9417c266d10f0730\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Sample_ID                                           590\\n\",\n",
    "      \"Site_ID                                             590\\n\",\n",
    "      \"ClimSST                                             590\\n\",\n",
    "      \"Temperature_Kelvin                                  590\\n\",\n",
    "      \"Temperature_Mean                                    590\\n\",\n",
    "      \"Temperature_Minimum                                 590\\n\",\n",
    "      \"Temperature_Maximum                                 590\\n\",\n",
    "      \"Temperature_Kelvin_Standard_Deviation               590\\n\",\n",
    "      \"Windspeed                                           590\\n\",\n",
    "      \"SSTA                                                590\\n\",\n",
    "      \"SSTA_Standard_Deviation                             590\\n\",\n",
    "      \"SSTA_Mean                                           590\\n\",\n",
    "      \"SSTA_Minimum                                        590\\n\",\n",
    "      \"SSTA_Maximum                                        590\\n\",\n",
    "      \"SSTA_Frequency                                      590\\n\",\n",
    "      \"SSTA_Frequency_Standard_Deviation                   590\\n\",\n",
    "      \"SSTA_FrequencyMax                                   590\\n\",\n",
    "      \"SSTA_FrequencyMean                                  590\\n\",\n",
    "      \"SSTA_DHW                                            590\\n\",\n",
    "      \"SSTA_DHW_Standard_Deviation                         590\\n\",\n",
    "      \"SSTA_DHWMax                                         590\\n\",\n",
    "      \"SSTA_DHWMean                                        590\\n\",\n",
    "      \"TSA                                                 590\\n\",\n",
    "      \"TSA_Standard_Deviation                              590\\n\",\n",
    "      \"TSA_Minimum                                         590\\n\",\n",
    "      \"TSA_Maximum                                         590\\n\",\n",
    "      \"TSA_Mean                                            590\\n\",\n",
    "      \"TSA_Frequency                                       590\\n\",\n",
    "      \"TSA_Frequency_Standard_Deviation                    590\\n\",\n",
    "      \"TSA_FrequencyMax                                    590\\n\",\n",
    "      \"TSA_FrequencyMean                                   590\\n\",\n",
    "      \"TSA_DHW                                             590\\n\",\n",
    "      \"TSA_DHW_Standard_Deviation                          590\\n\",\n",
    "      \"TSA_DHWMax                                          590\\n\",\n",
    "      \"TSA_DHWMean                                         590\\n\",\n",
    "      \"Depth_m                                             532\\n\",\n",
    "      \"Distance_to_Shore                                   590\\n\",\n",
    "      \"Exposure                                            590\\n\",\n",
    "      \"Turbidity                                           590\\n\",\n",
    "      \"Cyclone_Frequency                                   590\\n\",\n",
    "      \"Percent_Bleached                                    590\\n\",\n",
    "      \"is_dup                                              590\\n\",\n",
    "      \"Temperature_Kelvin_is_outlier                       590\\n\",\n",
    "      \"Temperature_Mean_is_outlier                         590\\n\",\n",
    "      \"Temperature_Minimum_is_outlier                      590\\n\",\n",
    "      \"Temperature_Maximum_is_outlier                      590\\n\",\n",
    "      \"Temperature_Kelvin_Standard_Deviation_is_outlier    590\\n\",\n",
    "      \"Windspeed_is_outlier                                590\\n\",\n",
    "      \"Depth_m_is_outlier                                  590\\n\",\n",
    "      \"Distance_to_Shore_is_outlier                        590\\n\",\n",
    "      \"any_outlier                                         590\\n\",\n",
    "      \"dtype: int64\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 7\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"Removing the outliers and 'na' values. Saving to the csv file\",\n",
    "   \"id\": \"dc9c4ca642d25221\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-11-12T10:16:22.283693Z\",\n",
    "     \"start_time\": \"2025-11-12T10:16:22.181413Z\"\n",
    "    }\n",
    "   },\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"clean_df, outlier_rows = clean_outliers(\\n\",\n",
    "    \"    df,\\n\",\n",
    "    \"    cols,\\n\",\n",
    "    \"    k_iqr=1.5,\\n\",\n",
    "    \"    strategy=\\\"drop\\\",\\n\",\n",
    "    \"    output_csv=\\\"../data/cleaned_data_dropped.csv\\\",\\n\",\n",
    "    \")\\n\",\n",
    "    \"clean_df.isna().sum()\"\n",
    "   ],\n",
    "   \"id\": \"237ec8bf14c207af\",\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Sample_ID                                0\\n\",\n",
    "       \"Site_ID                                  0\\n\",\n",
    "       \"ClimSST                                  0\\n\",\n",
    "       \"Temperature_Kelvin                       0\\n\",\n",
    "       \"Temperature_Mean                         0\\n\",\n",
    "       \"Temperature_Minimum                      0\\n\",\n",
    "       \"Temperature_Maximum                      0\\n\",\n",
    "       \"Temperature_Kelvin_Standard_Deviation    0\\n\",\n",
    "       \"Windspeed                                0\\n\",\n",
    "       \"SSTA                                     0\\n\",\n",
    "       \"SSTA_Standard_Deviation                  0\\n\",\n",
    "       \"SSTA_Mean                                0\\n\",\n",
    "       \"SSTA_Minimum                             0\\n\",\n",
    "       \"SSTA_Maximum                             0\\n\",\n",
    "       \"SSTA_Frequency                           0\\n\",\n",
    "       \"SSTA_Frequency_Standard_Deviation        0\\n\",\n",
    "       \"SSTA_FrequencyMax                        0\\n\",\n",
    "       \"SSTA_FrequencyMean                       0\\n\",\n",
    "       \"SSTA_DHW                                 0\\n\",\n",
    "       \"SSTA_DHW_Standard_Deviation              0\\n\",\n",
    "       \"SSTA_DHWMax                              0\\n\",\n",
    "       \"SSTA_DHWMean                             0\\n\",\n",
    "       \"TSA                                      0\\n\",\n",
    "       \"TSA_Standard_Deviation                   0\\n\",\n",
    "       \"TSA_Minimum                              0\\n\",\n",
    "       \"TSA_Maximum                              0\\n\",\n",
    "       \"TSA_Mean                                 0\\n\",\n",
    "       \"TSA_Frequency                            0\\n\",\n",
    "       \"TSA_Frequency_Standard_Deviation         0\\n\",\n",
    "       \"TSA_FrequencyMax                         0\\n\",\n",
    "       \"TSA_FrequencyMean                        0\\n\",\n",
    "       \"TSA_DHW                                  0\\n\",\n",
    "       \"TSA_DHW_Standard_Deviation               0\\n\",\n",
    "       \"TSA_DHWMax                               0\\n\",\n",
    "       \"TSA_DHWMean                              0\\n\",\n",
    "       \"Depth_m                                  0\\n\",\n",
    "       \"Distance_to_Shore                        0\\n\",\n",
    "       \"Exposure                                 0\\n\",\n",
    "       \"Turbidity                                0\\n\",\n",
    "       \"Cyclone_Frequency                        0\\n\",\n",
    "       \"Percent_Bleached                         0\\n\",\n",
    "       \"is_dup                                   0\\n\",\n",
    "       \"dtype: int64\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 8,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 8\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"pf_llm_env\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.12.7\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "9ffdb816132a6a42"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pf_llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
